<!DOCTYPE html><html lang="ko" mode="dark" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.2.1" /><meta property="og:title" content="[paper-review] TEBNER: Domain Specific Named Entity Recognition with Type Expanded Boundary-aware Network." /><meta property="og:locale" content="ko" /><meta name="description" content="Fang, Z., Cao, Y., Li, T., Jia, R., Fang, F., Shang, Y., &amp; Lu, Y. (2021, November). TEBNER: Domain Specific Named Entity Recognition with Type Expanded Boundary-aware Network. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (pp. 198-207)." /><meta property="og:description" content="Fang, Z., Cao, Y., Li, T., Jia, R., Fang, F., Shang, Y., &amp; Lu, Y. (2021, November). TEBNER: Domain Specific Named Entity Recognition with Type Expanded Boundary-aware Network. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (pp. 198-207)." /><link rel="canonical" href="https://good-riverdeer.github.io/posts/TEBNER/" /><meta property="og:url" content="https://good-riverdeer.github.io/posts/TEBNER/" /><meta property="og:site_name" content="good-riverdeer" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-01-17T14:30:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="[paper-review] TEBNER: Domain Specific Named Entity Recognition with Type Expanded Boundary-aware Network." /><meta name="twitter:site" content="@twitter_username" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"description":"Fang, Z., Cao, Y., Li, T., Jia, R., Fang, F., Shang, Y., &amp; Lu, Y. (2021, November). TEBNER: Domain Specific Named Entity Recognition with Type Expanded Boundary-aware Network. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (pp. 198-207).","url":"https://good-riverdeer.github.io/posts/TEBNER/","@type":"BlogPosting","headline":"[paper-review] TEBNER: Domain Specific Named Entity Recognition with Type Expanded Boundary-aware Network.","dateModified":"2022-02-09T11:37:14+09:00","datePublished":"2022-01-17T14:30:00+09:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://good-riverdeer.github.io/posts/TEBNER/"},"@context":"https://schema.org"}</script><title>[paper-review] TEBNER: Domain Specific Named Entity Recognition with Type Expanded Boundary-aware Network. | good-riverdeer</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="good-riverdeer"><meta name="application-name" content="good-riverdeer"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/school.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">good-riverdeer</a></div><div class="site-subtitle font-italic">딥러닝을 공부하는</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/good-riverdeer" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['riverdeer.youn','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>[paper-review] TEBNER: Domain Specific Named Entity Recognition with Type Expanded Boundary-aware Network.</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>[paper-review] TEBNER: Domain Specific Named Entity Recognition with Type Expanded Boundary-aware Network.</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> riverdeer </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Mon, Jan 17, 2022, 2:30 PM +0900" >Jan 17, 2022<i class="unloaded">2022-01-17T14:30:00+09:00</i> </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Wed, Feb 9, 2022, 11:37 AM +0900" >Feb 9, 2022<i class="unloaded">2022-02-09T11:37:14+09:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2271 words">12 min read</span></div></div><div class="post-content"><p><a href="https://aclanthology.org/2021.emnlp-main.18/">Fang, Z., Cao, Y., Li, T., Jia, R., Fang, F., Shang, Y., &amp; Lu, Y. (2021, November). TEBNER: Domain Specific Named Entity Recognition with Type Expanded Boundary-aware Network. In <em>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</em> (pp. 198-207).</a></p><p><em>개인적인 논문해석을 포함하고 있으며, 의역 및 오역이 남발할 수 있습니다. :)</em></p><p><br /></p><hr /><p><br /></p><h2 id="1-introduction">1. Introduction</h2><ul><li>현존하는 대부분의 NER 방법들은 많은 양의 labeled data가 필요함<ul><li>특정 도메인의 전문가가 직접 레이블링을 해야하는 경우, 사람의 노력이 많이 필요하며 시간도 많이 소요</ul><li>distant supervision: 자동적인 레이블링 할당 방법들이 제안되어 왔음<ul><li>특정 도메인에 대한 <code class="language-plaintext highlighter-rouge">raw corpus</code> 혹은 <code class="language-plaintext highlighter-rouge">dictionary</code>를 사용<li>정확한 문자열 매칭(string matching)으로 레이블을 할당<li>위 방법으로 진행할 경우, 아래 두 가지 문제점이 존재할 수 있음</ul></ul><ol><li><strong><em>Incomplete annotations</em></strong><ul><li>original dictionary에 entity가 모두 포함되지 않을 수 있음: <em>out-of-dictionary</em><ul><li>기존 데이터셋에 <code class="language-plaintext highlighter-rouge">dictionary</code>가 전체 domain entity에 50% 정도만 포함하고 있음을 확인</ul><li>일부 선행 연구에서는 heuristic rule로 <code class="language-plaintext highlighter-rouge">dictionary</code>를 확장<ul><li>다른 도메인에 일반적으로 적용될 수 없음</ul></ul><li><strong><em>the difficulty of recalling new entities</em></strong><ul><li>supervised model을 통해 NER을 수행했던 선행 연구에서도 모델의 한계로 인해 새로운 entity를 찾아내는 것이 어려웠음<li>선행 연구에서는 <code class="language-plaintext highlighter-rouge">sequence label model</code>이나 <code class="language-plaintext highlighter-rouge">boundary detection model</code>과 같은 방식으로 사용, <strong>맥락적 정보(context information)</strong>만을 활용했음<ul><li><code class="language-plaintext highlighter-rouge">sequence label model</code>: 문장의 단어마다 레이블을 예측하는 모델링<li><code class="language-plaintext highlighter-rouge">boundary detection model</code>: 문장의 특정 구간이 entity임을 예측하는 모델링</ul><li>특정 도메인 corpus에 대한 <strong>전역적인 통계적 특징(global statistical features)</strong>은 선행 연구에서 배제되었음</ul></ol><ul><li><strong>TEBNER</strong>: Type Expanded Boundary-aware NER)<ul><li><strong><em>dictionary expansion</em></strong><ul><li>raw corpus에서 높은 퀄리티의 어구(phrase)을 추출, 잠재적인 entity로 간주<li>수집된 어구에 <em>entity typing model(with context information)</em>로 분류 및 필터링<li>필터링된 어구들을 <code class="language-plaintext highlighter-rouge">dictionary</code>에 추가<li><strong><em>Incomplete annotations</em></strong> 문제 완화</ul><li><strong><em>multi-granularity boundary labeling strategy</em></strong><ul><li>서로 다른 관점에서 문장 시퀀스를 태깅하고 이를 통해 명확한 entity boundary(문장 내 어느 범위가 entity인지)를 찾아냄<li>token interaction tagger: entity token 간의 내부적 연결성 관점<li>sequence labeling: 문장 내 명확한 entity 범위 관점<li>global statistical features: 특정 domain corpus의 전역적 관점</ul></ul></ul><h3 id="contributions">Contributions</h3><ul><li>애매한 방식이나 heuristic rule 등에 의존하지 않고 semantic context를 통한 새로운 <strong><em>dictionary extension method</em></strong>를 제안<li>word, sentence, corpus level의 정보들을 통합(fusing)하여 entity boundary를 특정할 수 있는 <strong><em>Multi-granularity boundary-aware network</em></strong> 제안<li>세 가지 벤치마크 데이터셋에 대한 폭넓은 실험 설계 및 결과 제시</ul><p><br /></p><hr /><p><br /></p><h2 id="2-related-work">2. Related Work</h2><h3 id="supervised-models">Supervised Models</h3><ul><li>최근 일부 연구에서는 각 entity의 범위(boundary)만을 찾아내는 연구가 일부 있음<ul><li><a href="https://arxiv.org/abs/1810.01808">Wang et al., 2018</a>; <a href="https://aclanthology.org/D19-1034.pdf">Zhang et al., 2019</a>; <a href="https://arxiv.org/abs/1910.11476">Li et al., 2020b</a></ul><li>사전학습 모델의 등장에 따라 ELMo(<a href="https://arxiv.org/abs/1802.05365">Peters et al., 2018</a>)나 BERT(<a href="https://arxiv.org/abs/1810.04805">Devlin et al.,2019</a>)를 사용하여 NER 태스크를 수행<li>많은 양의 labeled data가 필요함</ul><h3 id="distant-supervision-methods">Distant supervision methods</h3><ul><li>AutoNER; <a href="https://arxiv.org/abs/1809.03599">Shang et al., 2018b</a><ul><li><strong><em>out-of-dictionary</em></strong> 어구들을 <strong><em>unknown</em></strong> type으로 매칭<li>잠재적인 entity 후보로 선정</ul><li>HAMNER; <a href="https://ojs.aaai.org/index.php/AAAI/article/view/6358">Liu et al., 2020</a><ul><li><code class="language-plaintext highlighter-rouge">entity boundary</code>를 예측하는 entity classification model을 도입</ul></ul><p><br /></p><hr /><p><br /></p><h2 id="3-problem-definition">3. Problem Definition</h2><ul><li>Named Entity Recognition<ul><li>주어진 단어 시퀀스 $X = [x_1, x_2, …, x_n]$에서<li>$t$ 타입의 entity 범위 $e_t = \left[x_i, …, x_j\right] (0 \le i \le j \le n)$를 찾아냄</ul><li>Distant Supervision NER<ul><li><code class="language-plaintext highlighter-rouge">dictionary</code> $D$를 입력으로 제공<li><code class="language-plaintext highlighter-rouge">dictionary</code>는 이름(surface name)과 entity type을 적어놓음</ul></ul><p><br /></p><hr /><p><br /></p><h2 id="4-the-proposed-method">4. The Proposed Method</h2><ul><li>두 가지 요소로 구성<li>Dictionary Extender<ul><li>NER 레이블을 생성<li>target domain에 대해서 많은 어구(phrase)를 생성함</ul><li>Entity Recognizer<ul><li><code class="language-plaintext highlighter-rouge">entity boundary</code>와 <code class="language-plaintext highlighter-rouge">entity type</code>을 예측</ul></ul><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/67779236/149704739-c8bb0e16-c055-4dd0-a92e-119623569166.png" alt="image-description" width="500" /></p><p><br /><br /></p><h3 id="41-dictionary-extender">4.1. Dictionary Extender</h3><ul><li><strong><em>High-quality phrase extraction</em></strong><ul><li>선행 연구에서 처럼 AutoPhrase(<a href="https://ieeexplore.ieee.org/abstract/document/8306825">Shang et al., 2018a</a>)를 통한 어구 생성<li><strong>AutoPhrase</strong><ul><li>distantly supervised phrase mining tool<li>빈도 수에 따라 후보 어구를 만들고 검증하며 어구를 생성하는 툴</ul><li>Threshold<ul><li>좋은 퀄리티의 entity만을 확보하기 위한 임계값, AutoPhrase의 신뢰도 점수 기반<li>single word phrase: 0.9<li>multi-word phrase: 0.5</ul></ul></ul><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/67779236/149705316-4c449c9c-3caa-42e4-9fc0-ec21735a4e84.png" alt="image-description" /> <em>AutoPhrase의 아키텍처, <a href="https://ieeexplore.ieee.org/abstract/document/8306825">Shang et al., 2018a</a></em></p><ul><li><strong><em>Entity classification</em></strong><ul><li>AutoPhrase가 생성한 어구 리스트를 필터링하는 과정<ul><li><strong><em>Entity typing model</em></strong>을 아래와 같이 구성<li>일차적인 Entity 후보의 엔티티 타입을 예측<li>ex.) $none$ type으로 예측되는 경우 <code class="language-plaintext highlighter-rouge">dictionary</code>에서 제외</ul><li><code class="language-plaintext highlighter-rouge">PreTrained BERT &gt; Linear &gt; softmax</code>를 태워 <code class="language-plaintext highlighter-rouge">cross-entropy</code>로 학습<ul><li><code class="language-plaintext highlighter-rouge">BERT's input</code>: $[CLS] \space ctxt_l \space [x_i] \space … \space [x_j] \space ctxt_r \space [SEP]$ (텍스트 시퀀스)<li><code class="language-plaintext highlighter-rouge">Linear layer's input</code>: $V_h = V_{[cls]} \oplus V_{[x_i]} \oplus V_{[x_j]}$<li><code class="language-plaintext highlighter-rouge">Relu &gt; softmax</code>: $P(y_t\mid e_t) = softmax(W^2_t (Relu(W^1_t V_h + b^1_t)) + b^2_t)$<li><code class="language-plaintext highlighter-rouge">cross-entropy</code>: $L_{type} = -\sum_{i=1}^n y_i \log(P(y_i\mid e_i))$</ul><li>$none$ entity 추가<ul><li><strong><em>Entity typing model</em></strong>이 $none$ entity type을 식별할 수 있도록<li>AutoPhrase의 신뢰도 점수가 0.3보다 낮은 어구를 $none$ entity type으로 레이블링하여 학습 데이터에 추가</ul></ul><li><strong><em>Entity Filtering</em></strong><ul><li><strong><em>Entity typing model</em></strong>의 예측 값이…<ul><li>$none$ entity type으로 분류된 어구 제거<li>여러 entity type으로 분류 예측된 어구 제거<li>남은 어구들을 <code class="language-plaintext highlighter-rouge">original dictionary</code>에 추가하여 확장<li>구성된 <code class="language-plaintext highlighter-rouge">dictionary</code>를 entity recognizer의 학습에 사용</ul></ul></ul><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/67779236/153002199-17fb6fad-3d99-4fdb-8f81-19554bf981d2.png" alt="image-description" width="500" /></p><p><br /><br /></p><h3 id="42-entity-recognizer">4.2. Entity Recognizer</h3><ul><li><strong><em>개요</em></strong><ul><li>distantly supervised 방식으로 레이블이 할당된 데이터는 error가 포함할 확률이 높음<li><code class="language-plaintext highlighter-rouge">entity boundary detection</code> &amp; <code class="language-plaintext highlighter-rouge">entity classification</code>을 동시에 모델링할 경우 과적합될 가능성이 높음<li><strong>따라서</strong>, <code class="language-plaintext highlighter-rouge">boundary</code>, <code class="language-plaintext highlighter-rouge">type classification</code>을 각각 학습<ul><li>Section 4.1.은 <code class="language-plaintext highlighter-rouge">type classification</code>의 학습 (<strong><em>Entity typing model</em></strong>)<li>Section 4.2.는 <code class="language-plaintext highlighter-rouge">boundary</code>의 학습 (token interaction model $M_w$, sequence label model $M_s$의 학습)</ul><li>아래 3가지의 tagging schema를 fusing하여 다방면의 정보(multi-granularity)를 종합<ul><li>“Break or Tie” Tagging Schema ($M_w$)<li>“BIO” Tagging Schema ($M_s$)<li>“Phrase Matching” Tagging Schema (AutoPhrase)</ul></ul></ul><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/67779236/149708907-89ac7aff-8f74-438a-999f-9affad7afc50.png" alt="image-description" /></p><ul><li><strong><em>“Break or Tie” Tagging Schema</em></strong><ul><li>for <strong>word level</strong> entity boundary ($M_w$)<li>entity가 분절되는 토큰들에 “Break”<li>entity가 지속되는 토큰들에 “Tie”<li>$M_w$: output representation from <code class="language-plaintext highlighter-rouge">BERT</code>에 대해 아래와 같은 방식으로 학습<ul><li> \[V^\prime_i = concatenate(i\text{-th token}, i+1\text{-th token})\]<ul><li>$i$번째 representation과 $i+1$번째 representation의 특징 결합</ul><li> \[P(c_i|V^\prime_i) = {\exp(c^T_i V^\prime_i) \over \sum_{c_k\in C} \exp(c^T_k V^\prime_i)}\]<ul><li>$C = \set{[Break], [Tie]}$<li>$P(c_i\mid V^\prime_i)$: $V_i^\prime$이 토큰 $c_i$가 될 확률</ul></ul></ul></ul><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/67779236/149708061-e2cf9071-fb35-47bf-8408-f20038f65c7f.png" alt="image-description" /> <em>“Break or Tie”, 파란색 entity는 모델이 인식하지 못하는 경우를 가정</em></p><ul><li><strong><em>“BIO” Tagging Schema</em></strong><ul><li>for <strong>word level</strong> entity boundary ($M_s$)<li>기존의 NER 태깅 방식과 동일<li>entity 범위가 시작하는 지점에 “B”<li>entity 범위가 지속되는 지점에 “I”<li>entity 범위에 속하지 않는 지점에 “O”<li>$M_s$: <code class="language-plaintext highlighter-rouge">BERT &gt; Linear &gt; softmax</code> 학습<ul><li>$C = \set{[B], [I], [O]}$</ul></ul></ul><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/67779236/149708302-e07a89e2-44a6-4b4b-b1ba-da79cbaa25c7.png" alt="image-description" /> <em>“BIO”, 파란색 entity는 모델이 인식하지 못하는 경우를 가정</em></p><ul><li><strong><em>“Phrase Matching” Tagging Schema</em></strong><ul><li>for <strong>corpus level</strong> entity boundary<li>선행 연구들은 corpus 내부의 통계적 특징들을 간과함<li>AutoPhrase의 결과를 태깅<ul><li><em>corpus의 통계적 특징들을 반영한 AutoPhrase의 결과를 태깅했으니 통계적 요소를 반영하였다고 생각하는듯…?!</em></ul></ul></ul><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/67779236/149708527-cab7f4e0-2e76-4c90-ac5e-4c44e70bc761.png" alt="image-description" /> <em>“Phrase Matching”, 파란색 entity는 모델이 인식하지 못하는 경우를 가정</em></p><ul><li><strong><em>결론</em></strong><ul><li>각기 다른 entity tagging 방식을 결합하여 마지막 분류의 입력으로 사용</ul></ul><h3 id="algorithm-the-process-of-tebner">Algorithm: The process of TEBNER</h3><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/67779236/153109670-1713af79-7e0a-4a2e-a7b9-1cb8e678b414.png" alt="image-description" /></p><p><br /></p><hr /><p><br /></p><h2 id="5-experiments">5. Experiments</h2><h3 id="51-experiment-setup">5.1. Experiment Setup</h3><ul><li><strong>Dataset</strong><ul><li><strong>BC5CDR</strong><ul><li>Chemical and Disease domain</ul><li><strong>NCBI-Disease</strong><ul><li>Disease domain</ul><li><strong>LaptopReview</strong><ul><li>review sentences<li>AspectTerm mentions</ul></ul><li><strong>Training Details</strong><ul><li>사전 학습 가중치<ul><li>biomedical domain: <code class="language-plaintext highlighter-rouge">"biobert-base-cased-v1.1"</code><li>technical domain: <code class="language-plaintext highlighter-rouge">"bert-base-cased"</code></ul><li>maximum sentence length: <code class="language-plaintext highlighter-rouge">256 tokens</code><li>hidden representation size: <code class="language-plaintext highlighter-rouge">786</code><li>learning rate: <code class="language-plaintext highlighter-rouge">3e-5</code><li>dropout probability: <code class="language-plaintext highlighter-rouge">0.15</code><li><code class="language-plaintext highlighter-rouge">AdamW</code> optimizer<li>Multi-layer perceptron for “entity classifier”: <strong>a depth of 2 and a hidden size of 256</strong></ul></ul><p><br /><br /></p><h3 id="52-comparing-with-previous-work">5.2. Comparing with Previous Work</h3><ul><li><strong>Baselines</strong><ul><li>supervised model<ul><li><strong>BiLSTM-CRF</strong><li><strong>ELMo-NER</strong><li><strong>BERT-NER</strong></ul><li>distantly supervised model<ul><li><strong>Dictionary Match</strong>: 주어진 <code class="language-plaintext highlighter-rouge">dictionary</code> $D$의 단순 string matching<li><strong>SwellShark</strong>: biomedical 도메인에 특화된 방법, regular expressions가 필요하며 특별한 케이스에 대해선 직접 조정이 필요함<li><strong>AutoNER</strong>: BiLSTM 모델을 사용해 인접 토큰들의 연결성을 학습, <code class="language-plaintext highlighter-rouge">false-negative labels</code>의 수를 줄임<li><strong>HAMNER</strong>: 기존 SOTA, headword-based matching을 통해 <code class="language-plaintext highlighter-rouge">dictionary</code>를 확장하고 entity typing model로 entity 범위(spans)를 예측</ul></ul><li><strong>Results</strong><ul><li><strong>AutoNER</strong> &amp; <strong>HAMNER</strong>과 동일한 <code class="language-plaintext highlighter-rouge">dictionary</code> &amp; phrases를 사용하였음에도 더 좋은 성능<li><strong>SwellShark</strong>가 biomedical 도메인에 특화된 구조이지만 더 나은 성능<li><strong>AutoNER</strong>도 “Break or Tie” tagging을 적용해 다방면의 정보를 종합하고자 했으나 인접한 토큰들의 연결성만을 모델링하여 성능이 떨어짐</ul></ul><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/67779236/149711852-97a5fb87-d92b-4ce4-b370-2dd9005b1033.png" alt="image-description" /></p><p><br /><br /></p><h3 id="53-impact-of-different-modules">5.3. Impact of Different Modules</h3><ul><li><strong><em>Effectiveness of Dictionary Extension</em></strong><ul><li>복잡한 방법들을 사용하지 않았음<ul><li>ex). headword matching, semantic similarity calculation, annotations weight setting)</ul><li>문맥적 의미 정보만을 사용해 <code class="language-plaintext highlighter-rouge">dictionary</code> 확장<ul><li>어느 domain에나 적용할 수 있음</ul></ul></ul><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/67779236/149712286-2058f8fc-a7a8-406d-98f3-519dd6c184c3.png" alt="image-description" /></p><ul><li><strong><em>Influence of the number of Annotations</em></strong><ul><li>확장한 <code class="language-plaintext highlighter-rouge">dictionary</code>로 만든 distantly annotations의 수를 조절하며 성능 비교<li>데이터의 수가 늘어날수록 증가하다가 80% 부근에서 수렴하는 경향이 있음</ul></ul><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/67779236/149712836-b262c47f-8e81-49fb-af97-03d14521d8bf.png" alt="image-description" /></p><ul><li><strong><em>Ablation studies</em></strong></ul><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/67779236/149712947-d9074f89-da98-432c-b3d9-cbae2a4d204d.png" alt="image-description" /></p><p><br /></p><hr /><p><br /></p><h2 id="6-conclusion">6. Conclusion</h2><ul><li>새로운 dictionary extension 방법 제안<li>distant supervision 방식으로 특정 도메인에 적합한 boundary-aware model을 설계<li>어느 도메인에서나 적용될 수 있도록 entity classification model을 사용해 <code class="language-plaintext highlighter-rouge">dictionary</code>를 확장하였음<li>3가지 tagging schema를 적용해, 지역적 &amp; 전역적 측면에서의 entity 인식을 시도하였음</ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/paper-review/'>paper-review</a>, <a href='/categories/natural-language-processing/'>Natural Language Processing</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/deep-learning/" class="post-tag no-text-decoration" >deep_learning</a> <a href="/tags/named-entity-recognition/" class="post-tag no-text-decoration" >Named_Entity_Recognition</a> <a href="/tags/ner/" class="post-tag no-text-decoration" >NER</a> <a href="/tags/bert/" class="post-tag no-text-decoration" >BERT</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=[paper-review] TEBNER: Domain Specific Named Entity Recognition with Type Expanded Boundary-aware Network. - good-riverdeer&url=https://good-riverdeer.github.io/posts/TEBNER/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=[paper-review] TEBNER: Domain Specific Named Entity Recognition with Type Expanded Boundary-aware Network. - good-riverdeer&u=https://good-riverdeer.github.io/posts/TEBNER/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=[paper-review] TEBNER: Domain Specific Named Entity Recognition with Type Expanded Boundary-aware Network. - good-riverdeer&url=https://good-riverdeer.github.io/posts/TEBNER/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/DDPM/">[paper-review] Denoising diffusion probabilistic models</a><li><a href="/posts/SLidR/">[paper-review] Image-to-Lidar Self-Supervised Distillation for Autonomous Driving Data</a><li><a href="/posts/TEBNER/">[paper-review] TEBNER: Domain Specific Named Entity Recognition with Type Expanded Boundary-aware Network.</a><li><a href="/posts/EfficientNet/">[paper-review] EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</a><li><a href="/posts/Vision_Transformer/">[paper-review] An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/deep-learning/">deep_learning</a> <a class="post-tag" href="/tags/transformer/">transformer</a> <a class="post-tag" href="/tags/autonomous-driving/">autonomous_driving</a> <a class="post-tag" href="/tags/distillation/">distillation</a> <a class="post-tag" href="/tags/document-understanding/">document_understanding</a> <a class="post-tag" href="/tags/lidar/">lidar</a> <a class="post-tag" href="/tags/multimodal/">multimodal</a> <a class="post-tag" href="/tags/named-entity-recognition/">Named_Entity_Recognition</a> <a class="post-tag" href="/tags/ner/">NER</a> <a class="post-tag" href="/tags/ocr/">ocr</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/NEEDLE/"><div class="card-body"> <span class="timeago small" >Feb 16, 2022<i class="unloaded">2022-02-16T14:30:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[paper-review] Named Entity Recognition with Small Strongly Labeled and Large Weakly Labeled Data</h3><div class="text-muted small"><p> Jiang, H., Zhang, D., Cao, T., Yin, B., &amp; Zhao, T. (2021). Named entity recognition with small strongly labeled and large weakly labeled data. arXiv preprint arXiv:2106.08977. 개인적인 논문해석을 포함하고 ...</p></div></div></a></div><div class="card"> <a href="/posts/ArcFace_project/"><div class="card-body"> <span class="timeago small" >Sep 30, 2021<i class="unloaded">2021-09-30T12:20:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[project-review] ArcFace를 활용한 한국인 안면 인식</h3><div class="text-muted small"><p> 개요 이번 학기 학부 졸업 프로젝트 과제의 주제로 현재 COVID-19의 확산과 무인화 경향에 힘입어 “딥러닝 기반 얼굴인식을 활용한 본인인증 시스템”을 개발해보았다. 이번 포스팅에서는 위와 같은 프로젝트 수행 과정에서 ArcFace를 활용한 얼굴인식 모델을 구현해보는 과정을 간략하게 소개한다. 1. ArcFace를 활용한 안면인식 모델 개발 ...</p></div></div></a></div><div class="card"> <a href="/posts/EfficientNet/"><div class="card-body"> <span class="timeago small" >Oct 7, 2021<i class="unloaded">2021-10-07T20:48:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[paper-review] EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</h3><div class="text-muted small"><p> Tan, M., &amp; Le, Q. (2019, May). Efficientnet: Rethinking model scaling for convolutional neural networks. In International Conference on Machine Learning (pp. 6105-6114). PMLR. 개인적인 논문해석을 포함하고 ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/Donut/" class="btn btn-outline-primary" prompt="Older"><p>[paper-review] Donut: Document Understanding Transformer without OCR</p></a> <a href="/posts/NEEDLE/" class="btn btn-outline-primary" prompt="Newer"><p>[paper-review] Named Entity Recognition with Small Strongly Labeled and Large Weakly Labeled Data</p></a></div><div id="disqus_thread" class="pt-2 pb-2"><p class="text-center text-muted small"> Comments powered by <a href="https://disqus.com/">Disqus</a>.</p></div><script type="text/javascript"> var disqus_config = function () { this.page.url = 'https://good-riverdeer.github.io/posts/TEBNER/'; this.page.identifier = '/posts/TEBNER/'; }; /* Lazy loading */ var disqus_observer = new IntersectionObserver(function (entries) { if(entries[0].isIntersecting) { (function () { var d = document, s = d.createElement('script'); s.src = 'https://.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); disqus_observer.disconnect(); } }, { threshold: [0] }); disqus_observer.observe(document.querySelector('#disqus_thread')); /* Auto switch theme */ function reloadDisqus() { /* Disqus hasn't been loaded */ if (typeof DISQUS === "undefined") { return; } if (document.readyState == 'complete') { DISQUS.reset({ reload: true, config: disqus_config }); } } const modeToggle = document.querySelector(".mode-toggle"); if (modeToggle !== null) { modeToggle.addEventListener('click', reloadDisqus); window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', reloadDisqus); } </script></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://github.com/good-riverdeer">riverdeer</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/deep-learning/">deep_learning</a> <a class="post-tag" href="/tags/transformer/">transformer</a> <a class="post-tag" href="/tags/autonomous-driving/">autonomous_driving</a> <a class="post-tag" href="/tags/distillation/">distillation</a> <a class="post-tag" href="/tags/document-understanding/">document_understanding</a> <a class="post-tag" href="/tags/lidar/">lidar</a> <a class="post-tag" href="/tags/multimodal/">multimodal</a> <a class="post-tag" href="/tags/named-entity-recognition/">Named_Entity_Recognition</a> <a class="post-tag" href="/tags/ner/">NER</a> <a class="post-tag" href="/tags/ocr/">ocr</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script>
