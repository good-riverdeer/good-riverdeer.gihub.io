<!DOCTYPE html><html lang="ko" mode="dark" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.2.1" /><meta property="og:title" content="[paper-review] Named Entity Recognition with Small Strongly Labeled and Large Weakly Labeled Data" /><meta property="og:locale" content="ko" /><meta name="description" content="Jiang, H., Zhang, D., Cao, T., Yin, B., &amp; Zhao, T. (2021). Named entity recognition with small strongly labeled and large weakly labeled data. arXiv preprint arXiv:2106.08977." /><meta property="og:description" content="Jiang, H., Zhang, D., Cao, T., Yin, B., &amp; Zhao, T. (2021). Named entity recognition with small strongly labeled and large weakly labeled data. arXiv preprint arXiv:2106.08977." /><link rel="canonical" href="https://good-riverdeer.github.io/posts/NEEDLE/" /><meta property="og:url" content="https://good-riverdeer.github.io/posts/NEEDLE/" /><meta property="og:site_name" content="good-riverdeer" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-02-16T14:30:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="[paper-review] Named Entity Recognition with Small Strongly Labeled and Large Weakly Labeled Data" /><meta name="twitter:site" content="@twitter_username" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"description":"Jiang, H., Zhang, D., Cao, T., Yin, B., &amp; Zhao, T. (2021). Named entity recognition with small strongly labeled and large weakly labeled data. arXiv preprint arXiv:2106.08977.","url":"https://good-riverdeer.github.io/posts/NEEDLE/","@type":"BlogPosting","headline":"[paper-review] Named Entity Recognition with Small Strongly Labeled and Large Weakly Labeled Data","dateModified":"2022-02-16T14:30:00+09:00","datePublished":"2022-02-16T14:30:00+09:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://good-riverdeer.github.io/posts/NEEDLE/"},"@context":"https://schema.org"}</script><title>[paper-review] Named Entity Recognition with Small Strongly Labeled and Large Weakly Labeled Data | good-riverdeer</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="good-riverdeer"><meta name="application-name" content="good-riverdeer"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/school.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">good-riverdeer</a></div><div class="site-subtitle font-italic">딥러닝을 공부하는</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/good-riverdeer" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['riverdeer.youn','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>[paper-review] Named Entity Recognition with Small Strongly Labeled and Large Weakly Labeled Data</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>[paper-review] Named Entity Recognition with Small Strongly Labeled and Large Weakly Labeled Data</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> riverdeer </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Wed, Feb 16, 2022, 2:30 PM +0900" >Feb 16, 2022<i class="unloaded">2022-02-16T14:30:00+09:00</i> </span></div><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="4769 words">26 min read</span></div></div><div class="post-content"><p><a href="https://arxiv.org/pdf/2106.08977.pdf">Jiang, H., Zhang, D., Cao, T., Yin, B., &amp; Zhao, T. (2021). Named entity recognition with small strongly labeled and large weakly labeled data. <em>arXiv preprint arXiv:2106.08977.</em></a></p><p><em>개인적인 논문해석을 포함하고 있으며, 의역 및 오역이 남발할 수 있습니다. :)</em></p><p><br /></p><hr /><p><br /></p><h2 id="1-introduction">1. Introduction</h2><p>Deep learning 방식의 NER은 많은 데이터를 필요로 합니다. NER task에 대한 레이블링 작업은 token-level의 레이블링이 필요하기 때문에 시간적, 금전적 비용이 많이 들고, 작업자의 실수가 발생할 수도 있습니다. 이러한 요소들이 의료 도메인과 같은 전분 분야 특정 도메인에 대한 NER을 어렵게 만드는 요인입니다. 때문에 선행 연구에서는 labeled data가 한정적인 경우를 대응하기 위한 연구들을 진행했습니다.</p><ul><li><strong><em>continually pre-train</em></strong><ul><li>큰 규모의 unlabeled data를 사용하는 방법<ul><li>거대한 unlabeled open-domain data에 대해 <strong>사전학습을 진행한 BERT가 대표적 예시</strong><li>이러한 open-domain pre-trained model은 특정 도메인 고유의 정보의 모델링 능력이 떨어짐</ul><li><strong><em>continually pre-train</em></strong>: <a href="https://academic.oup.com/bioinformatics/article/36/4/1234/5566506?login=true">Lee et al. (2020)</a>; <a href="https://aclanthology.org/2020.acl-main.740/">Gururangan et al. (2020)</a><ul><li>이미 학습된 open-domain pre-trained model을 이어서 사전 학습하는 방법을 제안<li>open-domain pre-trained model이 특정 도메인의 지식을 갖도록 하기 위함</ul></ul><li><strong><em>weak supervision</em></strong><ul><li>도메인 지식 베이스에서 자동적으로 label을 생성하는 방법<li><a href="https://aclanthology.org/D18-1230/">Shang et al. (2018)</a><ul><li>“Biomedical dictionary”를 통해 unlabeled Biomedical documents에 레이블을 자동 생성</ul></ul></ul><p>사람이 직접 생성하는 <strong>strongly labeled data</strong>는 위에서 언급한 것처럼 비용이 많이 소요되기 때문에 적은 양일 경우가 많습니다. 반면에 엄청난 양의 large scale unlabeled data와 전문 분야 domain knowledge를 이용해 자동적으로 생성하는 <strong>weakly labeled data</strong>는 그 양을 많이 확보할 수 있죠.</p><p>논문에서 저자들은 Weak labels가 아래 세 가지 특징을 가진다고 말합니다.</p><ul><li><strong>incompleteness</strong>: 세상에 존재하는 모든 entity를 지식 베이스가 모두 커버할 수 없음<li><strong>labeling bias</strong>: 자동적으로 생성되는 weak label은 entity가 아닌 것을 entity라고 할당하는 등의 노이즈가 발생<li><strong>ultra-large scale</strong>: 자동으로 생성될 수 있기 때문에 strong label에 비해 그 수가 많음</ul><p>위 특징을 가진 Weakly labeled data를 잘 활용할 수 있는 방법은 무엇일까요? 논문에서는 <strong>ultra-large scale</strong>의 특성으로 인해 유용한 도메인 지식은 확보할 수 있으나, 동시에 많은 양의 데이터가 <strong>incompleteness</strong>, <strong>labeling bias</strong>의 특성을 가지고 있기 때문에 이에 따른 노이즈의 영향도 많아질 수 밖에 없다고 말합니다. 때문에 NER 모델의 학습에 (Strongly + Weakly)의 단순히 조합하는 방식이나 label에 따른 가중치를 매겨 조합하는 방식 모두 <strong>incompleteness</strong>, <strong>labeling bias</strong> 특성이 야기하는 노이즈에 영향을 받을 수 있다고 말합니다.</p><p>이를 해결하고자 논문에서는 프레임워크 NEEDLE을 제안합니다.</p><ul><li>NEEDLE; Noise-aware wEakly supErviseD continuaL prE-training<ul><li>Stage 1<ul><li>open-domain pre-trained model을 target domain에 대해 사전학습<li>특정 도메인(target domain)의 큰 규모의 unlabeled data를 이용</ul><li>Stage 2<ul><li>target domain의 지식 베이스를 통해 unlabeled data에 weak label을 자동 생성<li>(Strongly labeled data + Weakly labeled data)를 이용 NER 학습</ul><li>Stage 3<ul><li>Strongly labeled data만으로 다시 한번 NER 학습</ul></ul></ul><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/67779236/154254624-1fd44830-9bcb-44c8-ad3b-dbe908cf7d09.png" alt="image-description" /></p><h3 id="contributions">Contributions</h3><ul><li>(Strong labels + Weak labels)의 단순한 조합, 가중치를 부여한 조합을 사용해 학습하는 경우 모델 성능이 떨어질 수 있음을 보임<ul><li>압도적인 양(<strong>ultra-large scale</strong>)을 가진 weak label의 노이즈 영향 때문</ul><li>세 단계의 프레임워크 NEEDLE을 제안, 압도적인 양의 weak label의 영향을 줄임<ul><li>다양한 실험 환경<ul><li>E-commerce query (온라인 쇼핑몰 검색어) NER task<li>Biomedical NER task<li>multi-lingual 환경</ul></ul></ul><p><br /></p><hr /><p><br /></p><h2 id="2-preliminaries">2. Preliminaries</h2><h3 id="21-named-entity-recognition">2.1. Named Entity Recognition</h3><p>NER(Named Entity Recognition)은?</p><ul><li>$N$개의 tokens로 이루어진 한 문장 $\mathbf X = [x_1, …, x_N]$에 대해서 한 토큰 범위 (a span of tokens) $s = [x_i, …, x_j] (0 \le i \le j \le N)$를 하나의 엔티티(an entity)로 가집니다.<li>$\mathbf X$에 대한 레이블 시퀀스(a sequence of labels) $\mathbf Y = [y_1, …, y_N]$는 <code class="language-plaintext highlighter-rouge">BIO</code> tag를 가지는 토큰 시퀀스입니다.<ul><li><code class="language-plaintext highlighter-rouge">BIO</code><ul><li><code class="language-plaintext highlighter-rouge">X</code> entity type의 $s$의 첫 토큰은 <code class="language-plaintext highlighter-rouge">B-X</code><li>이후 $s$의 다른 토큰들은 <code class="language-plaintext highlighter-rouge">I-X</code><li>entity가 아닌 토큰들은 <code class="language-plaintext highlighter-rouge">O</code></ul></ul><li><code class="language-plaintext highlighter-rouge">BIO</code>로 구성된 a sequence of token labels $\mathbf Y$를 예측하는 것이 NER(Named Entity Recognition) task라고 할 수 있습니다.<li><strong>Supervised NER</strong><ul><li>$M$개의 주어진 문장과 이미 label이 할당된 집합 $\set{(\mathbf X_m, \mathbf Y_m)}^M_{m=1}$, NER 모델 $f(\mathbf X; \theta)$에 대해 아래의 목적함수 최적화하며 학습하는 전형적인 딥러닝의 학습 기반 방법입니다.<li> \[\hat\theta = \arg\min_{\theta} {1 \over M} \sum^M_{m=1} l(\mathbf Y_m, f(\mathbf X_m; \theta))\]<li>$l(\cdot, \cdot)$: cross-entropy loss</ul><li><strong>Weakly Supervised NER</strong><ul><li>반면에 $\set{\mathbf Y_m}^M_{m=1}$을 자동으로 생성한 weakly labeled data로 교체하여 위와 동일한 목적함수를 통해 학습하는 방법을 말합니다.</ul></ul><p><br /></p><hr /><p><br /></p><h2 id="3-method">3. Method</h2><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/67779236/154254624-1fd44830-9bcb-44c8-ad3b-dbe908cf7d09.png" alt="image-description" /></p><h3 id="31-stage-1-domain-continual-pre-training-over-unlabeled-data">3.1. Stage 1: Domain Continual Pre-training over Unlabeled Data</h3><p>선행 연구를 따라 the large in-domain unlabeled data \(\set{\tilde{\mathbf X}_m}^{\tilde M}_{m=1}\)을 사용해 사전 학습된 언어 모델 \(f_{LM}(\cdot; \theta_{enc}, \theta_{LM})\)을 추가 학습하는 과정입니다. 논문에서는 Masked Language Model 사전 학습 task를 이용해 학습한다고 언급했습니다. <em>이를 통해 Introduction에서 언급했던 특정 분야 도메인에 모델을 적응할 수 있게 할 수 있습니다.</em></p><ul><li>masked language model: 언어 모델의 사전 학습에 가장 많이 사용되는 학습 방법 (Devlin et al. (2019) 참조)<li>$\theta_{enc}$: 언어 모델 encoder의 parameter, 예) BERT의 parameter<li>$\theta_{LM}$: token classification head의 parameter, 예) fully-connected layer의 parameter</ul><p><br /></p><h3 id="32-stage-2-noise-aware-continual-pre-training-over-both-strongly-and-weakly-labeled-data">3.2. Stage 2: Noise-Aware Continual Pre-training over both Strongly and Weakly labeled Data</h3><p>본격적으로 NER을 학습하기 이전에 대규모의 weakly labeled data를 만들어내야 합니다. 논문에서는 전문 용어 사전(dictionary)을 구축하고 이 용어 사전 내 단어와 정확한 string matching이 발생하는 구간을 태깅하는 방식을 사용합니다. 이에 대한 자세한 설명은 논문의 <strong><em>Appendix E</em></strong>를 참고하면 되겠습니다.</p><p>자동 생성된 weakly labeled data: \(\set{(\tilde{\mathbf X}_m, \tilde{\mathbf Y}_m^w)}^{\tilde M}_{m=1}\) 를 사용해 <code class="language-plaintext highlighter-rouge">BERT-CRF</code>구조의 모델로 본격적인 NER 학습이 진행됩니다. 이 때 모델의 가중치는 Stage 1의 <code class="language-plaintext highlighter-rouge">BERT</code> parameter(\(\theta_{enc}\)) + 랜덤하게 초기화된 CRF layer의 parameter(\(\theta_{CRF}\)) 조합으로 구성됩니다.</p><p>이 모델에 약간의 Strongly labeled data를 통한 NER 학습을 진행시킨 뒤(Initial model) 논문의 주요 기여점이라 할 수 있는 <strong><em>Weak Label Completion</em></strong>과 <strong><em>Noise-Aware Loss Function</em></strong>의 테크닉을 적용해 Strongly + Weakly labeled data 모두 사용해 본격적인 학습이 시작됩니다.</p><ul><li><strong><em>Weak Label Completion</em></strong><ul><li>해당 테크닉은 Initial model의 예측 값으로 weak label을 대체하는 과정이라고 요약할 수 있는데, 간단하게 입력값(inputs)과 출력값(output)을 수식으로 표현할 수 있습니다.<li>inputs<ul><li>a sentence $\tilde{\mathbf{X}} = [x_1, …, x_N]$<li>the original weak labels $\tilde{\mathbf{Y}^w} = [y_1^w, …, y_M^w]$<li>the predictions from the initial model $\tilde{\mathbf Y}^p = \arg\min_{\mathbf Y} l(\mathbf Y, f(\tilde{\mathbf X}; \theta_{enc}, \theta_{CRF})) = [y_1^p, …, y_N^p]$</ul><li>output<ul><li>$\tilde{\mathbf Y}^c = [y_1^c, …, y_N^c]$<li> \[y_i^c = \begin{cases} y_i^p &amp;&amp; \text{if } y_i^w = \bigcirc \\ y_i^w &amp;&amp; \text{otherwise}\end{cases}\]<li>weak label이 <code class="language-plaintext highlighter-rouge">O</code>; non entity로 태깅되었다면, 모델의 예측 값을 사용<li>weak label이 <code class="language-plaintext highlighter-rouge">B-X</code> 혹은 <code class="language-plaintext highlighter-rouge">I-X</code>와 같이 entity로 태깅되었다면 weak label을 그대로 사용</ul><li><strong><em>누락된 entity를 Strong label에 학습한 모델의 힘을 빌려 weakly label의 불완전성을 보완하는 효과를 얻을 수 있을 것 같습니다.</em></strong></ul><li><strong><em>Noise-Aware Loss Function</em></strong><ul><li>저자들은 <strong>Introduction</strong>에서도 언급했듯이 weak labels은 <strong>ultra-large scale</strong>의 특성을 가지므로 불완전한 weakly labeled data 분포에 모델이 지나치게 적합되는 것을 완화하고자 했습니다. 따라서, <strong>Weak Label Completion</strong> 테크닉으로 수정된 corrected weak labels $\tilde{\mathbf Y^c}$의 신뢰도를 기반으로 한 손실함수를 제안합니다.<ul><li><code class="language-plaintext highlighter-rouge">confidence</code>: $\hat P(\tilde{\mathbf Y}^c = \tilde{\mathbf Y} \mid \tilde{\mathbf X})$: $\tilde{\mathbf Y}^c$가 실제 label이 될 것으로 추정되는 확률<li><code class="language-plaintext highlighter-rouge">confidence</code>가 높은 경우 log-likelihood<li><code class="language-plaintext highlighter-rouge">confidence</code>가 낮은 경우 log-<strong>un</strong>likelihood</ul></ul></ul>\[\begin{aligned} &amp; l_{NA}(\tilde{\mathbf Y}^c, f(\tilde{\mathbf X}_m; \theta)) \\ &amp;= \mathbb E_{\tilde{\mathbf Y}_m = \tilde{\mathbf Y}^c_m \mid \tilde{\mathbf X}_m} \mathcal L(\tilde{\mathbf Y}^c, f(\tilde{\mathbf X}_m; \theta), \mathbb 1(\tilde{\mathbf Y}_m = \tilde{\mathbf Y}_m^c)) \\ &amp;= \hat P(\tilde{\mathbf Y}^c = \tilde{\mathbf Y} \mid \tilde{\mathbf X})l(\tilde{\mathbf Y}^c, f(\tilde{\mathbf X}; \theta)) + P(\tilde{\mathbf Y}^c \ne \tilde{\mathbf Y} \mid \tilde{\mathbf X})l^-(\tilde{\mathbf Y}^c, f(\tilde{\mathbf X}; \theta)) \end{aligned}\] \[\begin{aligned} &amp; l(\tilde{\mathbf Y}^c, f(\tilde{\mathbf X}; \theta)) = -\log P_{f(\mathbf X; \theta)}(\mathbf Y) &amp;\\ &amp;l^-(\tilde{\mathbf Y}^c, f(\tilde{\mathbf X}; \theta)) = -\log [1 - P_{f(\mathbf X; \theta)}(\mathbf Y)] \end{aligned}\]<ul><li><code class="language-plaintext highlighter-rouge">confidence</code> 추정 (<strong><em>Appendix A</em></strong>)<ul><li>corrected weak label의 <code class="language-plaintext highlighter-rouge">confidence</code>, $\hat P(\tilde{\mathbf Y}^c = \tilde{\mathbf Y} \mid \tilde{\mathbf X})$를 추정하는 과정은 <strong><em>Appendix A</em></strong>에서 다루고 있습니다. 최종적으로는 original weak label과 model prediction의 신뢰도의 선형 결합으로 추정하게 됩니다.<ul><li>original weak label이 model prediction과 일치하는 경우 weak label의 신뢰도 가중<li>original weak label이 model prediction과 일치하지 않는 경우 model prediction의 신뢰도를 가중</ul><li>이 때 model prediction의 신뢰도; $\hat P(\tilde{\mathbf Y}^p = \tilde{\mathbf Y} \mid \tilde{\mathbf X})$의 추정은 CRF score의 분포에 histogram binning을 적용하고 각 bin에 대해 validation set에 대한 결과를 바탕으로 <code class="language-plaintext highlighter-rouge">confidence</code>를 추정합니다. <em>추정 방법에 대해서는 정확히 이해하지 못하였습니다…ㅜ</em><li><code class="language-plaintext highlighter-rouge">confidence</code>가 너무 높은 경우에는 이를 완화하는 후처리 작업도 진행했습니다.<ul><li>$P(\tilde{\mathbf Y}^c = \tilde{\mathbf Y} \mid \tilde{\mathbf X}) = \min(0.95, P(\tilde{\mathbf Y}^c = \tilde{\mathbf Y} \mid \tilde{\mathbf X}))$</ul></ul></ul><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/67779236/154609112-62ff2549-98cc-4a72-8516-b5e064a39886.png" alt="image-description" /> <em>corrected weak label의 신뢰도는 weak label &amp; model prediction의 신뢰도 선형 결합으로 정의된다.</em></p><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/67779236/154789394-944eba4b-56a4-4d38-bf9b-96f18272b0d9.png" alt="image-description" /> <em>논문에서 제시한 예시, CRF score histogram bin과 <code class="language-plaintext highlighter-rouge">confidence</code>의 상관관계를 확인할 수 있다.</em></p><ul><li><strong><em>Noise-Aware Loss Function</em></strong>의 해석<ul><li>이렇게 정의된 Noise-aware loss를 자세히 살펴보면 log-<strong>un</strong>likelihood loss는 <strong>regularization term</strong>으로 보이고, <code class="language-plaintext highlighter-rouge">confidence</code>는 loss term (여기서는 log-likelihood)과 regularization term (여기서는 log-<strong>un</strong>likelihood) 사이의 가중을 결정하는 <strong>adaptive weight</strong>로 보이기도 합니다.</ul><li>최종 손실함수<ul><li>최종적으로 Stage 2의 Initial model 학습에 strongly labeled data에 대해서는 일반적인 negative log-likelihood를, weakly labeled data에 대해서는 <strong><em>Noise-Aware Loss Function</em></strong>를 사용하게 됩니다.</ul></ul>\[\min_\theta {1\over M+\tilde M} \left[ \sum^M_{m=1} l(\mathbf Y_m, f(\mathbf X_m ;\theta)) + \sum^{\tilde M}_{m=1}l_{NA}(\tilde{\mathbf Y^c}_m, f(\tilde{\mathbf X_m}; \theta))\right]\]<p><br /></p><h3 id="33-stage-3-final-fine-tuning">3.3 Stage 3: Final Fine-tuning</h3><p>Stage 2에서 Initial model을 만들었던 방법대로 Strongly labeled data에 다시 한 번 최종적으로 미세 조정하게 됩니다. <strong>Experiment</strong> 파트에서 이 효과를 설명하고 있습니다.</p><p><br /></p><hr /><p><br /></p><h2 id="4-experiments">4. Experiments</h2><ul><li>baseline models<ul><li>transformer-based open-domain pretrained models + CRF<li>e.g., <code class="language-plaintext highlighter-rouge">BERT</code>, <code class="language-plaintext highlighter-rouge">mBERT</code>, <code class="language-plaintext highlighter-rouge">RoBERTa-Large</code> + CRF</ul><li><code class="language-plaintext highlighter-rouge">BIO</code> tagging scheme으로 entity tagging<li><code class="language-plaintext highlighter-rouge">Adam</code> optimizer</ul><h3 id="41-datasets">4.1. Datasets</h3><ul><li>E-commerce query domain<ul><li>English NER<ul><li>10 different entity types</ul><li>multilingual NER<ul><li>12 different entity types</ul><li>unlabeled in-domain data &amp; weak annotation<ul><li>쇼핑 웹사이트(Amazon)의 사용자 행동 데이터를 수집</ul></ul><li>Biomedical domain<ul><li>unlabeled data<ul><li><code class="language-plaintext highlighter-rouge">PubMed 2019 baseline</code> 수집</ul><li>weak annotation<ul><li>수집한 <code class="language-plaintext highlighter-rouge">dictionary</code>에서 exact string matching을 통해 할당<li><em><code class="language-plaintext highlighter-rouge">dictionary</code>수집 방법에 대해선 언급하지 않았음</em></ul></ul><li>Weak labels performance<ul><li><code class="language-plaintext highlighter-rouge">Table 1</code>의 weak label이 strong(golden; <em>데이터셋이 제공하는 원래 label</em>) label과 비교<li>E-commerce query domain에서 golden label에 비해 <code class="language-plaintext highlighter-rouge">Recall</code> 값이 많이 떨어짐<li><em>entity가 아닌 것을 entity로 태깅하는 경우가 많은 것으로 보임</em></ul></ul><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/67779236/154636433-fb98cb01-f747-423c-8f61-c5d0ecaa4018.png" alt="image-description" /> <em>Table 1. E-commerce query domain의 Weak label의 퀄리티가 다소 떨어지는 것이 보인다.</em></p><p><br /></p><h3 id="42-baselines">4.2. Baselines</h3><ul><li>모든 baseline 모델들은 in-domain unlabeled data에 continually pre-training을 진행하였습니다 (Stage 1). baseline 모델들에 대한 설명은 생략…</ul><p><br /></p><h3 id="43-e-commerce-ner">4.3. E-commerce NER</h3><h3 id="431-main-results">4.3.1. Main Results</h3><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/67779236/154637841-e0a5162a-1961-4757-9d38-4926114e4265.png" alt="image-description" /></p><ul><li>weakly supervised baselines<ul><li>WSL(weakly supervised learning) 방식이 가장 성능이 떨어집니다. 이를 통해 weakly labeled data가 모델의 성능을 떨어뜨릴 수 있음을 알 수 있습니다.</ul><li>semi-supervised baselines<ul><li>재미있게도, semi-supervised 방식이 오히려 supervised 방식의 성능을 능가하는데, 모델이 만들어낸 pseudo label이 weak label보다 좋을 수 있다고 추정할 수 있습니다. 최종적으로 NEEDLE은 semi-supervised 방식보다 성능이 좋았으며 pseudo label만을 사용하는 것보다 적절한 weak label을 함께 활용하는 것이 좋을 수 있다고 저자는 말합니다.</ul></ul><h3 id="432-ablation">4.3.2. Ablation</h3><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/67779236/154638574-c3d9f845-795d-4d4a-824f-da64263aaa75.png" alt="image-description" /> <em>WLC - Weak label completion; NAL - Noise-aware loss function; FT - Final fine-tuning</em></p><p><br /></p><h3 id="44-biomedical-ner">4.4. Biomedical NER</h3><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/67779236/154639134-b3d0cc34-d745-468b-a630-464721026f16.png" alt="image-description" /></p><p><br /></p><h3 id="45-analysis">4.5. Analysis</h3><ul><li><strong>Size of Weakly Labeled Data</strong></ul><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/67779236/154639643-e303d1fa-623b-4735-b9d6-a7552af459ce.png" alt="image-description" /></p><ul><li><code class="language-plaintext highlighter-rouge">Figure 2(a)</code> &amp; <code class="language-plaintext highlighter-rouge">Figure 2(b)</code><ul><li>weakly labeled data의 양을 변경하며 실험했을 때, SST 방식은 성능 변화 폭이 미미했습니다. 반면 NEEDLE의 경우 weakly labeled data가 늘어날수록 성능 역시 향상되는 것을 볼 수 있고 NEEDLE이 weakly labeled data를 비교적 잘 활용하고 있다고 볼 수 있습니다.</ul><li><code class="language-plaintext highlighter-rouge">Figure 2(c)</code><ul><li>weakly labeled data의 수가 늘어날수록 fine-tuning 수행 유무에 따라 성능 차이가 벌어지는 것을 볼 수 있는데, final fine-tuning을 통해 학습할 유용한 정보가 있을 수 있음을 나타내고 있습니다.</ul><li><strong>Two Rounds of Stage 2 Training</strong><ul><li>Stage 3의 효과를 관찰한 저자들은 “Final fine-tuning” 대신 Stage 2의 학습을 한 번 더 수행하면 어떨지 실험을 진행했습니다. Stage 3 이후에,<ol><li>새로운 모델로 weak label을 수정<li>strongly + weakly labeled data로 noise-aware training을 지속<li>strongly labeled data로 final fine-tuning</ol><li>전체적인 학습 과정을 한 바퀴 더 돌렸을 때, 약간의 성능 향상이 있었습니다. 반면에 SST 방식, NEEDLE w/o NAL의 경우엔 변화가 없었음을 볼 수 있습니다. <em>Noise-aware loss가 없는 경우 Noise-aware loss가 주요 요소인 Stage 2를 한 바퀴 더 굴린다는 개념이 의미없는 행위라고 생각이 드네요.</em></ul><li><strong>Size of Strongly Labeled Data</strong><ul><li>이번에는 Stronly labeld data의 수를 조절하며 실험하는데, 30% ~ 50%의 strongly labeled data가 있으면 fully supervised 방식의 성능에 도달함을 확인했습니다. 또한 20%의 데이터만으로 다른 60% 데이터를 사용한 baseline의 성능과 동등함을 근거로 들며 3배 정도 strongly labeled data에 대해 효율적이라고 주장하고 있네요.</ul></ul><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/67779236/154644021-c173857c-70d5-4705-8dd9-ab86b84a80a3.png" alt="image-description" /> <em>Strongly labeled data의 1% 만으로도 70% 초반의 성능을 보인다.</em></p><p><br /></p><h3 id="46-weakly-label-errors-in-e-commerce-ner">4.6. Weakly Label Errors in E-commerce NER</h3><p>여기에서는 weak label이 유발하는 error에 대해서 이해하고, 이를 바로 잡을 수 있는 방법들에 대해 이야기합니다.</p><ul><li><strong>Label Distribution Mismatch</strong><ul><li>먼저 저자들은 weak label의 분포가 strong label의 분포와의 차이가 심하다고 말합니다. <code class="language-plaintext highlighter-rouge">Figure 4</code>에서도 볼 수 있듯이 분포가 많이 다릅니다. 반면 SST 방식의 모델이 만들어낸 pseudo label의 분포는 strong label의 분포와 거의 비슷한데, 이를 두고 SST 방식이 직접적으로 학습했을 때 성능이 좋은 이유라고 말합니다.</ul><li><strong>Systematical Error</strong><ul><li>저자들은 weakly labeled data의 시스템 내부적 error는 Stage 3; Final fine-tuning으로 쉽게 바로잡을 수 있다고 주장합니다. 여기서 예시로 들고 있는 “amiibo”는 “nintendo”사의 <code class="language-plaintext highlighter-rouge">Product Line</code> 중 하나입니다. 따라서 “amiibo” 앞에 나타나는 “zelda”나 “wario”와 같은 entity는 <code class="language-plaintext highlighter-rouge">Misc</code> 타입으로 태깅되는 것이 옳습니다. 하지만 weak label에는 이를 <code class="language-plaintext highlighter-rouge">Color</code> 타입이라고 잘못 태깅되어 있어 corrected weak label에도 <code class="language-plaintext highlighter-rouge">Color</code> 타입이라고 잘못 태깅되어 있죠.<li>Stage 2에서는 이러한 샘플들을 <code class="language-plaintext highlighter-rouge">Color + ProductLine</code> 조합으로 잘못 학습하지만 Stage 3에 가서 <code class="language-plaintext highlighter-rouge">Misc + ProductLine</code>의 조합이라고 쉽게 수정될 수 있습니다.<li>이와 같이 끝에 수정되는 방향이, 애초에 적은 양의 <code class="language-plaintext highlighter-rouge">Misc + ProductLine</code>의 옳게된 조합으로 학습되는 것보다 모델이 학습하기에 쉬운 방향이라고 주장하고 있습니다.</ul></ul><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/67779236/154791276-ea3df51a-f12e-42cd-971c-950d3e6aa831.png" alt="image-description" /></p><ul><li><strong>Entity <code class="language-plaintext highlighter-rouge">BIO</code> Sequence Mismatch in Weak Label Completion</strong><ul><li>Stage 2에서 <strong>Weak Label Completion</strong> 과정을 수행하는 과정에서 <code class="language-plaintext highlighter-rouge">BIO</code> 태깅 시퀀스가 깨져버리는 경우가 발생할 수 있습니다. 예를 들어 <code class="language-plaintext highlighter-rouge">B-ProductType</code> &gt; <code class="language-plaintext highlighter-rouge">O</code> &gt; <code class="language-plaintext highlighter-rouge">O</code>로 태깅되어 있던 시퀀스에서 첫 번째 <code class="language-plaintext highlighter-rouge">O</code> 태그가 <strong>Weak Label Completion</strong> 과정에 의해 수정되면서 <code class="language-plaintext highlighter-rouge">B-ProductType</code> &gt; <code class="language-plaintext highlighter-rouge">I-Color</code> &gt; <code class="language-plaintext highlighter-rouge">O</code>로 깨져버리는 경우죠.<li>저자들은 이러한 경우가 E-commerce English query 데이터의 1.39% 있었다고 말하고, 이 경우를 학습에서 제외하는 실험도 진행했습니다. 그 결과 F1 score 기준, Stage 2에서는 +1.07의 향상이 있었지만 마지막 Stage 3에서 -0.18의 성능 저하가 있었다고 밝힙니다.<li>이 결과 굳이 해당 샘플들을 제거하는 과정은 필요없다고 결론짓고 있습니다.</ul><li><strong>Quantify the Impace of Weak Labels</strong><ul><li>여기에서는 구체적인 비교를 통해 weak label을 대하는 NEEDLE 프레임워크의 효용성을 밝힙니다.<li>Stage 2의 Initial model은 2384개의 예측 오류를 가지는데, NEEDLE 프레임워크 종료 시점에는 이 중 454개의 오류가 해결되고 새로운 오류가 311개 추가됩니다. 여기에는 weak label만의 영향만 있는게 아니기 때문에 weak label에 대해서만으로 추리면 각각 171개, 93개로 관찰됩니다.<li>이 비율이 즉, <strong>“weak label을 바로 잡는 비율” = “NEEDLE이 바로 잡은 샘플 수” : “NEEDLE이 추가로 범한 예측 오류” = 171 : 93</strong>으로 그 비율이 $171/93 = 1.84 &gt; 1$로 영향이 적지 않고 NEEDLE이 weak label에 효용성이 있다고 말하고 있습니다.</ul></ul><p><br /></p><hr /><p><br /></p><h2 id="5-discussion-and-conclusion">5. Discussion and Conclusion</h2><p>본 연구는 fully weakly supervised 방식, semi-supervised 방식과 모두 연관성이 있습니다. 각각 weakly labeled data를 사용한다는 점, 전체 데이터셋 중 일부만 레이블이 할당되어 있다는 점에서 말이죠.</p><p>Fully weakly supervised NER 방식이 fully supervised 방식에 비해 성능이 떨어짐을 꼬집고 fully weakly supervised 방식은 실제 애플리케이션에는 적합하지 않은 방식이며 반면에 Semi-supervised 방식은 <strong>weak supervision</strong>을 활용하지 않아 부분적으로만 성능을 끌어올릴 수 있다고 볼 수 있습니다.</p><p>이전의 fully weakly supervised 방식의 연구들은 weak labels에 strong labels를 단순하게 섞어버려 학습하는데 이를 NEEDLE 프레임워크에서는 <strong>weak labels의 노이즈를 억제하는 방식으로 완화</strong>하고 있죠.</p><p>그런 의미에서 본 연구는 supervised NER과 weakly supervised NER을 연결하는 다리와 같은 연구라고 볼 수 있습니다.</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/paper-review/'>paper-review</a>, <a href='/categories/natural-language-processing/'>Natural Language Processing</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/deep-learning/" class="post-tag no-text-decoration" >deep_learning</a> <a href="/tags/named-entity-recognition/" class="post-tag no-text-decoration" >Named_Entity_Recognition</a> <a href="/tags/ner/" class="post-tag no-text-decoration" >NER</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=[paper-review] Named Entity Recognition with Small Strongly Labeled and Large Weakly Labeled Data - good-riverdeer&url=https://good-riverdeer.github.io/posts/NEEDLE/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=[paper-review] Named Entity Recognition with Small Strongly Labeled and Large Weakly Labeled Data - good-riverdeer&u=https://good-riverdeer.github.io/posts/NEEDLE/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=[paper-review] Named Entity Recognition with Small Strongly Labeled and Large Weakly Labeled Data - good-riverdeer&url=https://good-riverdeer.github.io/posts/NEEDLE/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/DDPM/">[paper-review] Denoising diffusion probabilistic models</a><li><a href="/posts/SLidR/">[paper-review] Image-to-Lidar Self-Supervised Distillation for Autonomous Driving Data</a><li><a href="/posts/TEBNER/">[paper-review] TEBNER: Domain Specific Named Entity Recognition with Type Expanded Boundary-aware Network.</a><li><a href="/posts/EfficientNet/">[paper-review] EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</a><li><a href="/posts/Vision_Transformer/">[paper-review] An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/deep-learning/">deep_learning</a> <a class="post-tag" href="/tags/transformer/">transformer</a> <a class="post-tag" href="/tags/autonomous-driving/">autonomous_driving</a> <a class="post-tag" href="/tags/distillation/">distillation</a> <a class="post-tag" href="/tags/document-understanding/">document_understanding</a> <a class="post-tag" href="/tags/lidar/">lidar</a> <a class="post-tag" href="/tags/multimodal/">multimodal</a> <a class="post-tag" href="/tags/named-entity-recognition/">Named_Entity_Recognition</a> <a class="post-tag" href="/tags/ner/">NER</a> <a class="post-tag" href="/tags/ocr/">ocr</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/TEBNER/"><div class="card-body"> <span class="timeago small" >Jan 17, 2022<i class="unloaded">2022-01-17T14:30:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[paper-review] TEBNER: Domain Specific Named Entity Recognition with Type Expanded Boundary-aware Network.</h3><div class="text-muted small"><p> Fang, Z., Cao, Y., Li, T., Jia, R., Fang, F., Shang, Y., &amp; Lu, Y. (2021, November). TEBNER: Domain Specific Named Entity Recognition with Type Expanded Boundary-aware Network. In Proceedings of...</p></div></div></a></div><div class="card"> <a href="/posts/ArcFace_project/"><div class="card-body"> <span class="timeago small" >Sep 30, 2021<i class="unloaded">2021-09-30T12:20:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[project-review] ArcFace를 활용한 한국인 안면 인식</h3><div class="text-muted small"><p> 개요 이번 학기 학부 졸업 프로젝트 과제의 주제로 현재 COVID-19의 확산과 무인화 경향에 힘입어 “딥러닝 기반 얼굴인식을 활용한 본인인증 시스템”을 개발해보았다. 이번 포스팅에서는 위와 같은 프로젝트 수행 과정에서 ArcFace를 활용한 얼굴인식 모델을 구현해보는 과정을 간략하게 소개한다. 1. ArcFace를 활용한 안면인식 모델 개발 ...</p></div></div></a></div><div class="card"> <a href="/posts/EfficientNet/"><div class="card-body"> <span class="timeago small" >Oct 7, 2021<i class="unloaded">2021-10-07T20:48:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[paper-review] EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</h3><div class="text-muted small"><p> Tan, M., &amp; Le, Q. (2019, May). Efficientnet: Rethinking model scaling for convolutional neural networks. In International Conference on Machine Learning (pp. 6105-6114). PMLR. 개인적인 논문해석을 포함하고 ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/TEBNER/" class="btn btn-outline-primary" prompt="Older"><p>[paper-review] TEBNER: Domain Specific Named Entity Recognition with Type Expanded Boundary-aware Network.</p></a> <a href="/posts/SLidR/" class="btn btn-outline-primary" prompt="Newer"><p>[paper-review] Image-to-Lidar Self-Supervised Distillation for Autonomous Driving Data</p></a></div><div id="disqus_thread" class="pt-2 pb-2"><p class="text-center text-muted small"> Comments powered by <a href="https://disqus.com/">Disqus</a>.</p></div><script type="text/javascript"> var disqus_config = function () { this.page.url = 'https://good-riverdeer.github.io/posts/NEEDLE/'; this.page.identifier = '/posts/NEEDLE/'; }; /* Lazy loading */ var disqus_observer = new IntersectionObserver(function (entries) { if(entries[0].isIntersecting) { (function () { var d = document, s = d.createElement('script'); s.src = 'https://.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); disqus_observer.disconnect(); } }, { threshold: [0] }); disqus_observer.observe(document.querySelector('#disqus_thread')); /* Auto switch theme */ function reloadDisqus() { /* Disqus hasn't been loaded */ if (typeof DISQUS === "undefined") { return; } if (document.readyState == 'complete') { DISQUS.reset({ reload: true, config: disqus_config }); } } const modeToggle = document.querySelector(".mode-toggle"); if (modeToggle !== null) { modeToggle.addEventListener('click', reloadDisqus); window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', reloadDisqus); } </script></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://github.com/good-riverdeer">riverdeer</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/deep-learning/">deep_learning</a> <a class="post-tag" href="/tags/transformer/">transformer</a> <a class="post-tag" href="/tags/autonomous-driving/">autonomous_driving</a> <a class="post-tag" href="/tags/distillation/">distillation</a> <a class="post-tag" href="/tags/document-understanding/">document_understanding</a> <a class="post-tag" href="/tags/lidar/">lidar</a> <a class="post-tag" href="/tags/multimodal/">multimodal</a> <a class="post-tag" href="/tags/named-entity-recognition/">Named_Entity_Recognition</a> <a class="post-tag" href="/tags/ner/">NER</a> <a class="post-tag" href="/tags/ocr/">ocr</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script>
